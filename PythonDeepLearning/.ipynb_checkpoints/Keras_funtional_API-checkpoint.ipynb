{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4976,
     "status": "ok",
     "timestamp": 1571119244620,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "Y5H90HV799Qn",
    "outputId": "4ce9fb71-cdaf-4055-aec1-3266618367a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n",
      "check tensorflow version :  2.0.0-rc2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Colab only\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "#import necessary libraries.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "layer = tf.keras.layers\n",
    "\n",
    "print('check tensorflow version : ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJFoQfErAF6a"
   },
   "source": [
    "# tf.data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hnpja8PJAF6b"
   },
   "source": [
    "tf.data API는 데이터셋을 모델에 연결해주기 위한 복합적인 입력 파이프라인을 구축할 수 있게 도와줍니다.\n",
    "\n",
    "다수의 분산된 파일로부터 통합된 데이터를 만들어야 하는 경우나, 데이터 전처리, 미니배치, 랜덤셔플링 등의 데이터 파이프라인을 위한 복잡한 구조를 높은 추상성으로 간단하게 제어할 수 있는 인터페이스를 제공합니다.\n",
    "\n",
    "https://www.tensorflow.org/guide/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnqHt2kqAF6c"
   },
   "source": [
    "### 1. from_tensor_slices : python으로부터 데이터 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1571127526668,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "97jjrn--AF6c",
    "outputId": "eba43bc6-0b39-42ad-a902-5458225df55a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(10,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))\n",
    "#tf.random.uniform 은 랜덤하게 계속 값을 바꿔준다 4*10 크기의 매트릭스 작성\n",
    "dataset1.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1196,
     "status": "ok",
     "timestamp": 1571127527926,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "VC3S7m7RAF6e",
    "outputId": "b7a969b8-8f92-410f-b453-61fab4d7abab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(100,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "   (tf.random.uniform([4]),\n",
    "    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
    "\n",
    "dataset2.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1571127527928,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "B5UHhKdyAF6g",
    "outputId": "2a6290bc-a8a1-4e15-f0df-da5c9d1dd91d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(10,), dtype=tf.float32, name=None),\n",
       " (TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(100,), dtype=tf.int32, name=None)))"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "dataset3.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1721,
     "status": "ok",
     "timestamp": 1571127529360,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "X0qQtfz7AF6i",
    "outputId": "8e5dbe4b-dcc2-4c44-98c5-ac5287fd0b1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=82868, shape=(10,), dtype=float32, numpy=\n",
      "array([0.7302425 , 0.8774078 , 0.2012831 , 0.8283515 , 0.8817512 ,\n",
      "       0.34979236, 0.59300554, 0.9763757 , 0.9535173 , 0.7186383 ],\n",
      "      dtype=float32)>, (<tf.Tensor: id=82869, shape=(), dtype=float32, numpy=0.1366874>, <tf.Tensor: id=82870, shape=(100,), dtype=int32, numpy=\n",
      "array([19, 24, 72,  6, 25, 46, 37,  8,  4, 10, 64, 69, 94, 99, 81, 99, 90,\n",
      "       84,  0, 83, 78,  0,  2, 90, 38, 61, 57, 42, 68, 83, 79, 62, 80, 33,\n",
      "        0, 43, 67, 54, 11, 83, 21, 63, 10, 82, 82, 48, 51,  8, 23, 81, 64,\n",
      "       90, 34, 16, 86, 54, 82, 46, 12, 30, 54, 98, 25, 64, 45, 15, 77, 66,\n",
      "       49, 56, 83, 63, 29, 38, 28,  9, 22, 92, 74, 25, 30, 54, 27,  7, 86,\n",
      "       87, 11, 79, 39, 65,  6, 81, 42, 54, 79, 39, 78, 63, 85, 16],\n",
      "      dtype=int32)>))\n",
      "(<tf.Tensor: id=82871, shape=(10,), dtype=float32, numpy=\n",
      "array([0.4468323 , 0.25774336, 0.20163035, 0.78347933, 0.39382374,\n",
      "       0.1381743 , 0.40146792, 0.45226252, 0.49606872, 0.16396439],\n",
      "      dtype=float32)>, (<tf.Tensor: id=82872, shape=(), dtype=float32, numpy=0.07730198>, <tf.Tensor: id=82873, shape=(100,), dtype=int32, numpy=\n",
      "array([53, 49, 21, 15, 30, 41, 91, 66, 46, 94, 16, 82, 59, 63, 85, 54, 31,\n",
      "       79, 76, 63, 93, 58, 31, 58, 55,  6,  0, 90, 63, 48, 31, 13, 43, 68,\n",
      "       91, 26, 36, 38, 66, 65, 50, 53, 73,  2, 33,  3, 36, 20, 62, 65, 89,\n",
      "       28, 98, 35, 72,  9,  8, 31,  8, 10, 39, 37, 77, 49, 94, 76, 26, 51,\n",
      "       60, 34, 77, 91, 39, 74, 30, 77, 65, 11, 75, 40, 48, 26,  9, 69, 37,\n",
      "       43, 57, 38, 81, 56, 42, 97, 72, 18, 28, 47, 28, 69, 85,  1],\n",
      "      dtype=int32)>))\n"
     ]
    }
   ],
   "source": [
    "for i in dataset3.take(2):\n",
    "    print(i)\n",
    "#     print(i[0])\n",
    "#     print('\\n-------------------------------------------------------------------\\n')\n",
    "#     print(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ekiwD7cZAF6k"
   },
   "source": [
    "메모리 공간 위 이미지를 가져오는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7gq61cVAF6l"
   },
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1162,
     "status": "ok",
     "timestamp": 1571127777914,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "cF7DVqezgoQK",
    "outputId": "6dc00614-b0ad-4f4c-a474-9af172f2c1cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28) (10000,)\n",
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f05b0a63b38>"
      ]
     },
     "execution_count": 153,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEfJJREFUeJzt3W2M1eWZx/HfJfjEgyAiOCARrbjS\nGBfXEY2iqVaMmkatGqwvNhq1NKYm26Qma9wXa+ILiW7b9AVpQq0prl3bJtWo8amu2cTdgJXRsIDO\ntoJiHMQBBZFnGLz2xRyaEflf13jOmXMOvb+fhDBzrrnn3HOGH+fMXP/7vs3dBaA8R7V7AgDag/AD\nhSL8QKEIP1Aowg8UivADhSL8QKEIP1Aowg8UanQr78zMuJwQGGHubsP5uIae+c3sajP7s5mtNbP7\nGvlcAFrL6r2238xGSfqLpPmS+iStkHSru78TjOGZHxhhrXjmnytprbu/5+77JP1W0vUNfD4ALdRI\n+KdL+nDI+321277EzBaaWY+Z9TRwXwCabMR/4efuSyQtkXjZD3SSRp75N0iaMeT9U2u3ATgCNBL+\nFZJmmdnpZnaMpO9JerY50wIw0up+2e/uA2Z2j6SXJY2S9Ji7v920mQEYUXW3+uq6M37mB0ZcSy7y\nAXDkIvxAoQg/UCjCDxSK8AOFIvxAoQg/UCjCDxSK8AOFIvxAoQg/UCjCDxSK8AOFaunW3Wg9s3iB\nV6OrOsePHx/W582bV1l78cUXG7rv7GsbNWpUZW1gYKCh+25UNvdIs1bi8swPFIrwA4Ui/EChCD9Q\nKMIPFIrwA4Ui/ECh6PP/jTvqqPj/9wMHDoT1M888M6zfddddYX337t2VtZ07d4Zj9+zZE9bfeOON\nsN5ILz/rw2ePaza+kblF1y9k38+heOYHCkX4gUIRfqBQhB8oFOEHCkX4gUIRfqBQDfX5zWy9pO2S\nDkgacPfuZkwKzRP1hKW8L3zFFVeE9SuvvDKs9/X1VdaOPfbYcOyYMWPC+vz588P6o48+Wlnr7+8P\nx2Zr5r9OP/1wxo0bV1n74osvwrG7du1q6L4PasZFPpe7+ydN+DwAWoiX/UChGg2/S/qjmb1pZgub\nMSEArdHoy/557r7BzKZIesXM/s/dXxv6AbX/FPiPAegwDT3zu/uG2t+bJD0tae5hPmaJu3fzy0Cg\ns9QdfjMba2bjD74t6SpJa5o1MQAjq5GX/VMlPV1bujha0n+4+0tNmRWAEVd3+N39PUl/38S5YATs\n27evofEXXHBBWJ85c2ZYj64zyNbEv/zyy2H9vPPOC+sPP/xwZa2npyccu3r16rDe29sb1ufO/cpP\nwF8SPa7Lli0Lxy5fvryytmPHjnDsULT6gEIRfqBQhB8oFOEHCkX4gUIRfqBQ1qzjfod1Z2atu7OC\nRNtEZ9/fbFls1C6TpIkTJ4b1/fv3V9aypauZFStWhPW1a9dW1hptgXZ1dYX16OuW4rnffPPN4djF\nixdX1np6evT5558P6/xvnvmBQhF+oFCEHygU4QcKRfiBQhF+oFCEHygUff4OkB3n3Ijs+/v666+H\n9WzJbib62rJjqhvtxUdHfGfXGLz11lthPbqGQMq/tquvvrqydsYZZ4Rjp0+fHtbdnT4/gGqEHygU\n4QcKRfiBQhF+oFCEHygU4QcK1YxTetGgVl5rcaitW7eG9Wzd+u7du8N6dAz36NHxP7/oGGsp7uNL\n0vHHH19Zy/r8l156aVi/+OKLw3q2LfmUKVMqay+91JrjL3jmBwpF+IFCEX6gUIQfKBThBwpF+IFC\nEX6gUGmf38wek/QdSZvc/ZzabZMk/U7STEnrJS1w97hhjI40ZsyYsJ71q7P6rl27Kmvbtm0Lx376\n6adhPdtrILp+IttDIfu6ssftwIEDYT26zmDGjBnh2GYZzjP/ryUduvPAfZJedfdZkl6tvQ/gCJKG\n391fk7TlkJuvl7S09vZSSTc0eV4ARli9P/NPdfeNtbc/ljS1SfMB0CINX9vv7h7tzWdmCyUtbPR+\nADRXvc/8/WbWJUm1vzdVfaC7L3H3bnfvrvO+AIyAesP/rKTbam/fJumZ5kwHQKuk4TezJyUtl/R3\nZtZnZndKWiRpvpm9K+nK2vsAjiDpz/zufmtF6dtNnkuxGu05Rz3lbE38tGnTwvrevXsbqkfr+bN9\n+aNrBCRp4sSJYT26TiDr0x9zzDFhffv27WF9woQJYX3VqlWVtex71t1d/RP0O++8E44diiv8gEIR\nfqBQhB8oFOEHCkX4gUIRfqBQbN3dAbKtu0eNGhXWo1bfLbfcEo495ZRTwvrmzZvDerQ9thQvXR07\ndmw4NlvamrUKozbj/v37w7HZtuLZ133SSSeF9cWLF1fW5syZE46N5vZ1jnvnmR8oFOEHCkX4gUIR\nfqBQhB8oFOEHCkX4gUJZK4+Hjrb7KlnWUx4YGKj7c1944YVh/fnnnw/r2RHcjVyDMH78+HBsdgR3\ntrX30UcfXVdNyq9ByI42z0Rf2yOPPBKOfeKJJ8K6uw+r2c8zP1Aowg8UivADhSL8QKEIP1Aowg8U\nivADhTqi1vNHa5WzfnO2/XW2Djpa/x2tWR+ORvr4mRdeeCGs79y5M6xnff5si+voOpJsr4Dse3rc\ncceF9WzNfiNjs+95Nvdzzz23spYdXd4sPPMDhSL8QKEIP1Aowg8UivADhSL8QKEIP1CotM9vZo9J\n+o6kTe5+Tu22ByR9X9LBRu397h43lIehkbXhI9krH2mXXXZZWL/pppvC+iWXXFJZy465ztbEZ338\nbC+C6HuWzS379xDtyy/F1wFk+1hkc8tkj9uOHTsqazfeeGM49rnnnqtrTocazjP/ryVdfZjbf+bu\nc2p/Gg4+gNZKw+/ur0na0oK5AGihRn7mv8fMVpnZY2Z2YtNmBKAl6g3/LyR9Q9IcSRsl/aTqA81s\noZn1mFlPnfcFYATUFX5373f3A+7+haRfSpobfOwSd+929+56Jwmg+eoKv5l1DXn3u5LWNGc6AFpl\nOK2+JyV9S9JkM+uT9K+SvmVmcyS5pPWSfjCCcwQwAorZt3/SpElhfdq0aWF91qxZdY/N+rZnnXVW\nWN+7d29Yj/YqyNalZ+fMf/TRR2E92/8+6ndnZ9jv27cvrI8ZMyasL1u2rLI2bty4cGx27UW2nj9b\nkx89bv39/eHY2bNnh3X27QcQIvxAoQg/UCjCDxSK8AOFIvxAoTqq1XfRRReF4x988MHK2sknnxyO\nnThxYliPlp5K8fLSzz77LBybLTfOWlZZyyvadjzberu3tzesL1iwIKz39MRXbUfHcJ94YrwkZObM\nmWE9895771XWsuPBt2/fHtazJb9ZCzVqNZ5wwgnh2OzfC60+ACHCDxSK8AOFIvxAoQg/UCjCDxSK\n8AOFanmfP+qXL1++PBzf1dVVWcv69Fm9ka2asy2ms157oyZMmFBZmzx5cjj29ttvD+tXXXVVWL/7\n7rvDerQkeM+ePeHY999/P6xHfXwpXobd6HLibClzdh1BND5bLnzaaaeFdfr8AEKEHygU4QcKRfiB\nQhF+oFCEHygU4QcK1dI+/+TJk/26666rrC9atCgcv27duspathVzVs+Oe45kPd+oDy9JH374YVjP\nts+O9jKItvWWpFNOOSWs33DDDWE9OgZbitfkZ9+T888/v6F69LVnffzsccuO4M5EezBk/56ifS8+\n/vhj7du3jz4/gGqEHygU4QcKRfiBQhF+oFCEHygU4QcKNTr7ADObIelxSVMluaQl7v5zM5sk6XeS\nZkpaL2mBu2+NPtfAwIA2bdpUWc/63dEa6ewY6+xzZz3nqK+b7bO+ZcuWsP7BBx+E9Wxu0X4B2Zr5\n7EyBp59+OqyvXr06rEd9/uzY9KwXn52XEB1Pnn3d2Zr6rBefjY/6/Nk1BNGR7tljMtRwnvkHJP3Y\n3b8p6SJJPzSzb0q6T9Kr7j5L0qu19wEcIdLwu/tGd3+r9vZ2Sb2Spku6XtLS2octlRRfCgago3yt\nn/nNbKak8yT9SdJUd99YK32swR8LABwhhh1+Mxsn6Q+SfuTunw+t+eACgcMuEjCzhWbWY2Y92c9w\nAFpnWOE3s6M1GPzfuPtTtZv7zayrVu+SdNjf5Ln7EnfvdvfuRhdDAGieNPw2+GvJX0nqdfefDik9\nK+m22tu3SXqm+dMDMFLSVp+kSyT9o6TVZraydtv9khZJ+r2Z3SnpA0nxWc4abN1s2LChsp4tL+7r\n66usjR07NhybbWGdtUg++eSTytrmzZvDsaNHxw9ztpw4aytFy2qzLaSzpavR1y1Js2fPDus7d+6s\nrGXt161bw85x+rhFc4/agFLeCszGZ0d0R0upt23bFo6dM2dOZW3NmjXh2KHS8Lv7/0iqakp+e9j3\nBKCjcIUfUCjCDxSK8AOFIvxAoQg/UCjCDxRqOH3+ptm9e7dWrlxZWX/qqacqa5J0xx13VNay7a2z\n45yzpa/RstqsD5/1fLMrH7MjwKPlzNnR5Nm1FdnR5Rs3bgzr0efP5pZdH9HI96zR5cKNLCeW4usI\nTj/99HBsf39/3fc7FM/8QKEIP1Aowg8UivADhSL8QKEIP1Aowg8UqqVHdJtZQ3d2zTXXVNbuvffe\ncOyUKVPCerZuPerrZv3qrE+f9fmzfnf0+aMtoqW8z59dw5DVo68tG5vNPRONj3rlw5F9z7Ktu6P1\n/KtWrQrHLlgQb53h7hzRDaAa4QcKRfiBQhF+oFCEHygU4QcKRfiBQrW8zx/tE5/1Rhtx+eWXh/WH\nHnoorEfXCUyYMCEcm+2Nn10HkPX5s+sMItGR6VJ+HUB0DoMUf0937NgRjs0el0w092zde7aPQfY9\nfeWVV8J6b29vZW3ZsmXh2Ax9fgAhwg8UivADhSL8QKEIP1Aowg8UivADhUr7/GY2Q9LjkqZKcklL\n3P3nZvaApO9LOng4/f3u/kLyuVp3UUELnX322WF98uTJYT3bA/7UU08N6+vXr6+sZf3sdevWhXUc\neYbb5x/OoR0Dkn7s7m+Z2XhJb5rZwSsYfubu/1bvJAG0Txp+d98oaWPt7e1m1itp+khPDMDI+lo/\n85vZTEnnSfpT7aZ7zGyVmT1mZidWjFloZj1m1tPQTAE01bDDb2bjJP1B0o/c/XNJv5D0DUlzNPjK\n4CeHG+fuS9y92927mzBfAE0yrPCb2dEaDP5v3P0pSXL3fnc/4O5fSPqlpLkjN00AzZaG3wa3QP2V\npF53/+mQ27uGfNh3Ja1p/vQAjJThtPrmSfpvSaslHVyfeb+kWzX4kt8lrZf0g9ovB6PP9TfZ6gM6\nyXBbfUfUvv0AcqznBxAi/EChCD9QKMIPFIrwA4Ui/EChCD9QKMIPFIrwA4Ui/EChCD9QKMIPFIrw\nA4Ui/EChhrN7bzN9IumDIe9Prt3WiTp1bp06L4m51auZczttuB/Y0vX8X7lzs55O3duvU+fWqfOS\nmFu92jU3XvYDhSL8QKHaHf4lbb7/SKfOrVPnJTG3erVlbm39mR9A+7T7mR9Am7Ql/GZ2tZn92czW\nmtl97ZhDFTNbb2arzWxlu48Yqx2DtsnM1gy5bZKZvWJm79b+PuwxaW2a2wNmtqH22K00s2vbNLcZ\nZvZfZvaOmb1tZv9Uu72tj10wr7Y8bi1/2W9moyT9RdJ8SX2SVki61d3faelEKpjZeknd7t72nrCZ\nXSZph6TH3f2c2m0PS9ri7otq/3Ge6O7/3CFze0DSjnaf3Fw7UKZr6MnSkm6QdLva+NgF81qgNjxu\n7Xjmnytprbu/5+77JP1W0vVtmEfHc/fXJG055ObrJS2tvb1Ug/94Wq5ibh3B3Te6+1u1t7dLOniy\ndFsfu2BebdGO8E+X9OGQ9/vUWUd+u6Q/mtmbZraw3ZM5jKlDTkb6WNLUdk7mMNKTm1vpkJOlO+ax\nq+fE62bjF35fNc/d/0HSNZJ+WHt525F88Ge2TmrXDOvk5lY5zMnSf9XOx67eE6+brR3h3yBpxpD3\nT63d1hHcfUPt702SnlbnnT7cf/CQ1Nrfm9o8n7/qpJObD3eytDrgseukE6/bEf4VkmaZ2elmdoyk\n70l6tg3z+AozG1v7RYzMbKykq9R5pw8/K+m22tu3SXqmjXP5kk45ubnqZGm1+bHruBOv3b3lfyRd\nq8Hf+K+T9C/tmEPFvM6Q9L+1P2+3e26SntTgy8D9GvzdyJ2STpL0qqR3Jf2npEkdNLd/1+Bpzqs0\nGLSuNs1tngZf0q+StLL259p2P3bBvNryuHGFH1AofuEHFIrwA4Ui/EChCD9QKMIPFIrwA4Ui/ECh\nCD9QqP8HS8xVdqsDFvAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test[0].shape,test[1].shape)\n",
    "images[0]\n",
    "print(images.shape)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(images[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1571127533456,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "A7oC4YPnAF6m",
    "outputId": "ccb07f1f-c78e-494c-802c-5c396f25ad5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = train\n",
    "#images, labels = train[0],train[1]\n",
    "images = images/255\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kiIdWIhpAF6p"
   },
   "source": [
    "### 2. TextLineDataset : text file로부터 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTxqPoQuAF6q"
   },
   "outputs": [],
   "source": [
    "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
    "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
    "\n",
    "file_paths = [\n",
    "    tf.keras.utils.get_file(file_name, directory_url+file_name)\n",
    "    for file_name in file_names ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1571127541821,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "NljnbVNIAF6r",
    "outputId": "a8811327-9e0b-46e5-e37c-1aac6695bcf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/root/.keras/datasets/cowper.txt', '/root/.keras/datasets/derby.txt', '/root/.keras/datasets/butler.txt']\n"
     ]
    }
   ],
   "source": [
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMN92ou3AF6u"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1199,
     "status": "ok",
     "timestamp": 1571127543428,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "4IApcQ4AAF6v",
    "outputId": "ac8f7465-fb91-47cb-be8d-445dbd4f8dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\xef\\xbb\\xbfAchilles sing, O Goddess! Peleus' son;\"\n"
     ]
    }
   ],
   "source": [
    "for line in dataset.take(1):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PW0ZlO4pAF6y"
   },
   "outputs": [],
   "source": [
    "new_dataset = dataset.shuffle(buffer_size=10000).batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1086,
     "status": "ok",
     "timestamp": 1571127545373,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "W1aFArSUAF60",
    "outputId": "6c805dba-b98b-4379-aefb-689428b9da0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'That draw \\xc3\\x86neas, urge them from the powers'\n",
      " b'Terrified at the stroke, the wounded Chief'\n",
      " b\"That seem'd a tower, and at Ulysses' side\"]\n"
     ]
    }
   ],
   "source": [
    "for line in new_dataset.take(1):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZWUZlU5AF61"
   },
   "source": [
    "### 3. TextLineDataset : csv 파일로부터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1144,
     "status": "ok",
     "timestamp": 1571127547649,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "xHhj3GJZAF62",
    "outputId": "c6693c99-4684-4e69-91de-5d6ea04fcc94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "32768/30874 [===============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  ...     deck  embark_town  alone\n",
       "0         0    male  22.0  ...  unknown  Southampton      n\n",
       "1         1  female  38.0  ...        C    Cherbourg      n\n",
       "2         1  female  26.0  ...  unknown  Southampton      y\n",
       "3         1  female  35.0  ...        C  Southampton      n\n",
       "4         0    male  28.0  ...  unknown   Queenstown      y\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "df = pd.read_csv(titanic_file, index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1196,
     "status": "ok",
     "timestamp": 1571127548165,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "IXuWLSmeAF64",
    "outputId": "cee1a772-12ac-4a86-c920-66d6ee68cd4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'survived'          : 0\n",
      "  'sex'               : b'male'\n",
      "  'age'               : 22.0\n",
      "  'n_siblings_spouses': 1\n",
      "  'parch'             : 0\n",
      "  'fare'              : 7.25\n",
      "  'class'             : b'Third'\n",
      "  'deck'              : b'unknown'\n",
      "  'embark_town'       : b'Southampton'\n",
      "  'alone'             : b'n'\n"
     ]
    }
   ],
   "source": [
    "titanic_slices = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "\n",
    "for feature_batch in titanic_slices.take(1):\n",
    "    for key, value in feature_batch.items():\n",
    "        print(\"  {!r:20s}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94yCh4b3AF66"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vl5vTiHmAF67"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-XSanJS99Qz"
   },
   "source": [
    "# keras model build\n",
    "\n",
    "keras에서 모델을 만들기 위해 알아야 할 3가지 자료형인 layer, tensor, model이 있다.\n",
    "layer는 인공신경망을 구성하는 하위 계층을 의미하고, tensor는 layer와 layer 사이의 입력과 출력을 말한다. TensorFlow는 flow graph의 형태이기 때문에 tensor는 데이터에 따라 계속 변하는 변동 변수이기 때문에 특정 값을 가진다고 할 수 없음. 그러나 tf 2.0부터 tensor의 값을 tensor.numpy()의 형태로 쉽게 확인할 수 있음. 마지막으로 model은 layer를 엮은 네트워크 객체라고 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQzYPc8d99Q1"
   },
   "outputs": [],
   "source": [
    "#layer는 tf.keras.layers 아래의 클래스로 만들 수 있다.\n",
    "d1 = tf.keras.layers.Dense(32, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1139,
     "status": "ok",
     "timestamp": 1571127551021,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "3KAyO91o99Q5",
    "outputId": "e3123fbb-0a37-4487-f5ea-a8cf10a46f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.core.Dense'>\n"
     ]
    }
   ],
   "source": [
    "print(type(d1)) #레이어의 타입을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1571127551022,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "WKxUmgGU99Q-",
    "outputId": "a93c5752-58c0-4f14-df74-f60d7f506c66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 각 layer 클래스는 method로 init, build, call를 갖는다. \n",
    "# init은 객체가 만들어지는 단계이고, tf.keras.layers.Dense(32, activation='relu')를 선언했을 때 실행된다.\n",
    "# build는 실제로 layer가 파라미터를 갖는 단계, call은 layer가 가진 parameter로 데이터를 계산하는 단계이다.\n",
    "\n",
    "print(d1.get_weights()) #weight는 build되지 않았기 때문에 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1457,
     "status": "ok",
     "timestamp": 1571127552160,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "3i4f9Zqp99RG",
    "outputId": "5e42633f-1996-4ba3-e436-2c27b4fddbee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of inputs <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "weights of d1 [array([[-0.04300751,  0.05442222, -0.06351914, ..., -0.02036378,\n",
      "        -0.05058224, -0.04598121],\n",
      "       [ 0.04205451,  0.01317964, -0.05481307, ...,  0.06202085,\n",
      "        -0.05788997,  0.03169934],\n",
      "       [ 0.00340967,  0.02817924, -0.06222881, ..., -0.02501181,\n",
      "        -0.06403959,  0.03601902],\n",
      "       ...,\n",
      "       [ 0.04079453,  0.07551283,  0.01522338, ..., -0.05446227,\n",
      "        -0.03851385,  0.05197797],\n",
      "       [-0.05028106,  0.04152895,  0.01364347, ..., -0.00920295,\n",
      "        -0.06866248, -0.02511162],\n",
      "       [ 0.07821571, -0.06525655,  0.08213391, ..., -0.06719542,\n",
      "         0.03864294,  0.01603279]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)] \n",
      "-------------------------------------------------\n",
      " weight shape :  (784, 32) \n",
      "-------------------------------------------------\n",
      " bias shape :  (32,)\n"
     ]
    }
   ],
   "source": [
    "# build는 layer가 첫 번째로 call됐을 때 파라미터를 생성함. 특정 데이터를 입력하기 애매하기 때문에 보통 tf.keras.Input을 사용함.\n",
    "inputs = tf.keras.Input(shape=(784)) #shape를 정해줌. \n",
    "#layer의 input shape이 정해져야 layer가 build 단계에서 파라미터의 shape을 결정할 수 있음.\n",
    "print('type of inputs', type(inputs))\n",
    "d1_output = d1(inputs)\n",
    "print('weights of d1', d1.get_weights(), \n",
    "      '\\n-------------------------------------------------\\n',\n",
    "      'weight shape : ', d1.get_weights()[0].shape,\n",
    "      '\\n-------------------------------------------------\\n',\n",
    "      'bias shape : ', d1.get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1571127552161,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "blVFGmVx99RK",
    "outputId": "99f7469d-18ea-4625-e87d-5535d9cbfe52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1_output의 타입 <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "[[0.         0.         0.         0.47436    0.         1.9658246\n",
      "  0.         0.3577869  0.         0.         4.2919083  0.\n",
      "  0.         0.         0.         0.         0.         0.69398415\n",
      "  2.7948136  0.6680365  1.4964756  0.         0.         0.\n",
      "  0.         0.         0.8824892  0.         0.5894671  1.7771622\n",
      "  0.         0.6382079 ]]\n"
     ]
    }
   ],
   "source": [
    "# build가 된 layer는 이제 입력으로 데이터를 받으면 output을 계산한다.\n",
    "d1_output = d1(np.ones([1,784], dtype=np.float32))\n",
    "print('d1_output의 타입', type(d1_output)) # 계산 결과의 자료형은 tensor\n",
    "print('\\n-------------------------------------------------\\n')\n",
    "print(d1_output.numpy()) #tf 2.0은 eager excution을 default로 제공하여 현재 tensor가 가지고 있는 값을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukx6TzCO99RO"
   },
   "outputs": [],
   "source": [
    "#model은 다음과 같이 첫 번째 layer의 input tensor와 마지막 layer의 output tensor를 입력 받아 생성한다.\n",
    "\n",
    "inputs = tf.keras.Input(shape=(64), name='data_input')\n",
    "d_1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "d_1_output = d_1(inputs)\n",
    "# d_1 = tf.keras.layers.Dense(32, activation='relu')(inputs)와 같이 init 후 inputs를 넣어서 build를 동시에 수행할 수 있음.\n",
    "d_2_output = tf.keras.layers.Dense(64, activation='relu')(d_1_output)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=d_2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1402,
     "status": "ok",
     "timestamp": 1571127553069,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "E7xs9VKC99RS",
    "outputId": "534784ac-aebf-47df-f07a-1d1c9f0de471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data_input (InputLayer)      [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "=================================================================\n",
      "Total params: 4,192\n",
      "Trainable params: 4,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1796,
     "status": "ok",
     "timestamp": 1571127553743,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "FTS5jydD99RV",
    "outputId": "4cb9ee93-a002-4647-89d4-004653dda9ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEnCAYAAABbpaNzAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nREQGYAZwoXUQRET0Lde/AXGbQ01MqZ6mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure you have already graphviz, pydot, pydotplus libraries.\n",
    "tf.keras.utils.plot_model(model, 'my_first_model_with_shape_info.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLT518BV99RZ"
   },
   "outputs": [],
   "source": [
    "## 1. Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DTzdVnFAF7R"
   },
   "source": [
    "### data pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJXqniXaAF7T"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1178,
     "status": "ok",
     "timestamp": 1571127554469,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "Yd8tGEzwAF7U",
    "outputId": "f61cc730-5b63-4c18-a3ed-d4262e26092e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train dataset :  (60000, 28, 28)\n",
      "The shape of test dataset :  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of train dataset : \", x_train.shape)\n",
    "print(\"The shape of test dataset : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Qim_352AF7X"
   },
   "outputs": [],
   "source": [
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1076,
     "status": "ok",
     "timestamp": 1571127556683,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "ZbFMPKx3AF7Z",
    "outputId": "2c1055de-e8c3-46f9-d9f7-2e00b37b637a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train dataset :  (60000, 28, 28, 1)\n",
      "The shape of test dataset :  (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of train dataset : \", x_train.shape)\n",
    "print(\"The shape of test dataset : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDQzqdmOAF7d"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32).repeat()\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ao-5MOdbAF7f"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35317,
     "status": "ok",
     "timestamp": 1571127594860,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "CL3b5k2IAF7h",
    "outputId": "e7b952ca-58a2-4554-a350-f3f2299afd8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train for 1875 steps\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2798 - sparse_categorical_accuracy: 0.9205\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1266 - sparse_categorical_accuracy: 0.9620\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9714\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9765\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0609 - sparse_categorical_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05b62325f8>"
      ]
     },
     "execution_count": 151,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "import math\n",
    "steps_per_epoch=math.ceil(60000/32)\n",
    "model.fit(train_ds, epochs=5, steps_per_epoch=steps_per_epoch)\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36118,
     "status": "ok",
     "timestamp": 1571124787998,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "LX9QKj0oAF7i",
    "outputId": "5a62d15f-05b1-4475-aa3f-b70188f69f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08317860521294958, 0.9744]"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVIZz8gaAF7k"
   },
   "outputs": [],
   "source": [
    "del model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZakYzlFUAF7l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJbgTQawAF7n"
   },
   "source": [
    "## 2. Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r77E3ChAF7n"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28,1))  # Returns a placeholder tensor\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1345,
     "status": "ok",
     "timestamp": 1571124801618,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "eZtD5ktXU3cK",
    "outputId": "dfb6c63f-f49b-48f9-95cb-0abb216c9d8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30822, shape=(32,), dtype=uint8, numpy=\n",
       "array([9, 5, 9, 1, 1, 3, 1, 0, 5, 3, 4, 9, 7, 5, 5, 7, 3, 6, 4, 7, 0, 7,\n",
       "       0, 4, 2, 7, 8, 1, 3, 2, 1, 5], dtype=uint8)>"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_ds))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1571127354498,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "1yPQEBsMfJ2D",
    "outputId": "deb6bba6-b035-406e-f540-0ca125f8ea28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36097,
     "status": "ok",
     "timestamp": 1571124838754,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "E1YnyOIuAF7t",
    "outputId": "f83acca4-b030-4907-fc5d-73fd8d93f3d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1875 steps\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2665 - sparse_categorical_accuracy: 0.9226\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9627\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9779\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05bf4a8c18>"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "import math\n",
    "steps_per_epoch=math.ceil(60000/32)\n",
    "model.fit(train_ds, epochs=5, steps_per_epoch=steps_per_epoch)\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2078,
     "status": "ok",
     "timestamp": 1571124843050,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "UuNlMKosAF7u",
    "outputId": "3b2b7395-a7c6-42bc-b696-05923daa5782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09213436866539791, 0.9731]"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bXrHWW7AF7v"
   },
   "outputs": [],
   "source": [
    "del model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ill1SARf99Rd"
   },
   "source": [
    "# Split pre-trained model for customized transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14154,
     "status": "ok",
     "timestamp": 1571125094365,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "Z5KfdwAS99Re",
    "outputId": "25309bc3-f08a-43d4-a18f-a42552483611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171450368/171446536 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# You can take famous image processing architecture, resnet101.\n",
    "\n",
    "\n",
    "#https://keras.io/applications/#usage-examples-for-image-classification-models\n",
    "\n",
    "'''\n",
    "include_top: whether to include the fully-connected layer at the top of the network.\n",
    "weights: one of None (random initialization) or 'imagenet' (pre-training on ImageNet).\n",
    "input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\n",
    "input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (299, 299, 3). It should have exactly 3 inputs channels, and width and height should be no smaller than 71. E.g. (150, 150, 3) would be one valid value.\n",
    "pooling: Optional pooling mode for feature extraction when include_top is False.\n",
    "None means that the output of the model will be the 4D tensor output of the last convolutional layer.\n",
    "'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor.\n",
    "'max' means that global max pooling will be applied.\n",
    "classes: optional number of classes to classify images into, only to be specified if include_top is  True, and if no weights argument is specified.\n",
    "'''\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(240, 240, 3))\n",
    "resnet101 = tf.keras.applications.ResNet101(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "#imagenet 에서 학습한 모델 가져오기\n",
    "#output 은 클래스의 갯수에 따라 달라지므로\n",
    "#inputtensor = 이미지의 shape 를 넣어주는 변수 즉 내가 정할 수 있음. 내 영상사이즈를 넣어주는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1102,
     "status": "ok",
     "timestamp": 1571125097736,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "h0792iNG99Ri",
    "outputId": "0a2e19bf-b81a-43f4-d501-c6a9156f579f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f05be7854e0>\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f05be785550>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f05be785ac8>\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x7f05be75cfd0>\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7f05bdf1c630>\n",
      "<tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f05bdee0cc0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f05bdf1c5f8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f05bdea1e80>\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x7f05bde10eb8>\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7f05bde10a90>\n"
     ]
    }
   ],
   "source": [
    "for l in resnet101.layers[:10]:\n",
    "  print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1PUTpd30Gec5KlpfMDKPg9-seIReY0wwE"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12064,
     "status": "ok",
     "timestamp": 1571126085507,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "nzdMSnqC99Rl",
    "outputId": "ebe4eb3b-80e4-4b07-d56f-b54bb29a19e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the architecture of resnet 101\n",
    "tf.keras.utils.plot_model(resnet101, 'resnet101.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcXDexqf99Rp"
   },
   "outputs": [],
   "source": [
    "model_input = resnet101.get_layer('input_1').input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFCPgNlJ99Rt"
   },
   "outputs": [],
   "source": [
    "model_output = resnet101.get_layer('conv4_block23_out').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJ-warkc99R1"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.Model(inputs=model_input, outputs=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1571126001487,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "BOeT6Az599R6",
    "outputId": "fa209849-6ad9-4a3e-a550-ae6465e8990c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 240, 240, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 246, 246, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 120, 120, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 120, 120, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 120, 120, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 122, 122, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 60, 60, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 60, 60, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 60, 60, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 60, 60, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 60, 60, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 60, 60, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 60, 60, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 60, 60, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 60, 60, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 60, 60, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 60, 60, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 60, 60, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 60, 60, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 60, 60, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 60, 60, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 60, 60, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 60, 60, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 60, 60, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 60, 60, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 60, 60, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 60, 60, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 60, 60, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 60, 60, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 60, 60, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 60, 60, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 60, 60, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 60, 60, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 30, 30, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 30, 30, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 30, 30, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 30, 30, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 30, 30, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 30, 30, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 30, 30, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 30, 30, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 30, 30, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 30, 30, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 30, 30, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 30, 30, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 30, 30, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 30, 30, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 30, 30, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 30, 30, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 30, 30, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 30, 30, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 30, 30, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 30, 30, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 30, 30, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 30, 30, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 30, 30, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 30, 30, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 30, 30, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 30, 30, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 30, 30, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 30, 30, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 30, 30, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 15, 15, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 15, 15, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 15, 15, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 15, 15, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 15, 15, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 15, 15, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 15, 15, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 15, 15, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 15, 15, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 15, 15, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 15, 15, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 15, 15, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 15, 15, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 15, 15, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 15, 15, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 15, 15, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 15, 15, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 15, 15, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 15, 15, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 15, 15, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 15, 15, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 15, 15, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 15, 15, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 15, 15, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 15, 15, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 15, 15, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 15, 15, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 15, 15, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 15, 15, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 15, 15, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 15, 15, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 15, 15, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 15, 15, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 15, 15, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 15, 15, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 15, 15, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 15, 15, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 15, 15, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 15, 15, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 15, 15, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 15, 15, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 15, 15, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 15, 15, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 15, 15, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 15, 15, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 15, 15, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 15, 15, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 15, 15, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 15, 15, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 15, 15, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 15, 15, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 15, 15, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 15, 15, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 15, 15, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 15, 15, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 15, 15, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 15, 15, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 15, 15, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 15, 15, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 15, 15, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 15, 15, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 15, 15, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 15, 15, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 15, 15, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 15, 15, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 15, 15, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 15, 15, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 15, 15, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 15, 15, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 15, 15, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 15, 15, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 15, 15, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 15, 15, 1024) 0           conv4_block23_add[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 27,659,648\n",
      "Trainable params: 27,576,832\n",
      "Non-trainable params: 82,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1571125629887,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "nAiZP4Nv99R-",
    "outputId": "046131da-5154-41a4-a014-d8b42da53da8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resnet101.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4794,
     "status": "error",
     "timestamp": 1571127012767,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "VP5Y5hZa99SF",
    "outputId": "010838e2-b4af-441b-acef-3745fcf9a32f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-ec866a90270b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnew_model2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_call_fn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_base_init\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     generic_utils.validate_kwargs(kwargs, {'trainable', 'dtype', 'dynamic',\n\u001b[0;32m--> 197\u001b[0;31m                                            'autocast'})\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# Object to store all thread local layer properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'input')"
     ]
    }
   ],
   "source": [
    "input = tf.keras.Input(shape=[240,240,3])\n",
    "feature_map = new_model(input)\n",
    "vector = tf.keras.layers.Flatten()(feature_map)\n",
    "x= tf.keras.layers.Dense(1024,activation='relu')(vector)\n",
    "x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(10,activation = 'softmax')(x)\n",
    "\n",
    "new_model2 = tf.keras.Model(input = input,output =output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7428,
     "status": "ok",
     "timestamp": 1571127043624,
     "user": {
      "displayName": "황재익",
      "photoUrl": "",
      "userId": "04432755077897078229"
     },
     "user_tz": -540
    },
    "id": "fSAlme4h99SK",
    "outputId": "205060c5-e8e2-4fac-c385-ad75497593b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30436"
      ]
     },
     "execution_count": 117,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = resnet101.predict(np.ones([1,240,240,3]))\n",
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChQXravqdw6L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras_funtional_API.ipynb의 사본",
   "provenance": [
    {
     "file_id": "https://github.com/hukim1112/computer_vision/blob/master/DeepLearning/keras/Keras_funtional_API.ipynb",
     "timestamp": 1571119211853
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
